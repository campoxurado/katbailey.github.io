<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>Topics in Machine Learning</title><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.com/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/impressConsole.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="ml.css" media="screen,projection"></link></head><body class="impress-not-supported"><div id="impress"><div class="step step-level-1" step="0" id="title" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0" data-z="0"><h1 id="machine-learning">Machine Learning</h1><p>An overview of topics and how they fit together.</p></div><div class="step step-level-1" step="1" id="definition" data-rotate-y="-90" data-x="0" data-y="0" data-rotate-x="0" data-rotate-z="0" data-scale="1" data-z="0"><p>Teaching a machine how to learn from and make predctions on data.</p></div><div class="step step-level-1" step="2" id="words" data-rotate-y="0" data-z="-2000" data-rotate-x="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0"><img src="images/mlwords.png"></img></div><div class="step step-level-1" step="3" id="supervised-unsupervised" data-z="0" data-y="1200" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0"><h1 id="supervised">Supervised</h1><p>or</p><h1 id="unsupervised">Unsupervised</h1><p>Different approaches for different types of problem</p></div><div class="step step-level-1" step="4" id="supervised" data-x="-1000" data-z="-1000" data-y="2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="id1">Supervised</h1><p>There's a particular piece of information - the <strong>outcome</strong> - you want to predict about each piece of data, and you have some data already labeled with this outcome that you can train on.</p><p>The outcome is also sometimes referred to as the <strong>dependent variable</strong>. The predictors are referred to as <strong>independent variables</strong>.</p></div><div class="step step-level-1" step="5" id="regression-classification" data-x="-1400" data-y="2500" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="-1000"><h1 id="regression">Regression</h1><p>or</p><h1 id="classification">Classification</h1><p>What type of question needs to be asked of your data?</p></div><div class="step step-level-1" step="6" id="classification" data-z="-2000" data-x="-2000" data-y="3000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="id2">Classification</h1><p>Question: <strong>Which class</strong> does this example belong to?</p><p>Dependent variable is <strong>qualitative / categorical</strong></p></div><div class="step step-level-1" step="7" id="labeled" data-y="3700" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="-2000" data-z="-2000"><h1 id="labeled-data">Labeled Data</h1><img src="images/labeled_data.png"></img></div><div class="step step-level-1" step="8" id="binary-classifier" data-rotate-y="-90" data-x="-3000" data-y="3700" data-rotate-x="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="binary-classification">Binary classification</h1><p>Standard example: classifying emails as spam or not spam</p></div><div class="step step-level-1" step="9" id="moar-labels" data-rotate-y="0" data-x="-2000" data-y="4500" data-rotate-x="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="moar-labels">Moar labels</h1><img src="images/labeled_data2.png"></img></div><div class="step step-level-1" step="10" id="multi-class-classifier" data-rotate-y="-90" data-x="-3000" data-y="4500" data-rotate-x="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="multi-class-classification">Multi-class classification</h1><p>Standard example: identifying hand-written digits</p></div><div class="step step-level-1" step="11" id="yet-moar-labels" data-rotate-y="0" data-x="-2000" data-y="5300" data-rotate-x="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="moar-labels-for-everyone">Moar labels for everyone!</h1><img src="images/labeled_data3.png"></img></div><div class="step step-level-1" step="12" id="multi-label-classifier" data-rotate-y="-90" data-x="-3000" data-y="5300" data-rotate-x="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="multi-label-classification">Multi-label classification</h1><p>Each example could fall into multiple categories. E.g. Yelp restaurants categorized as "Mexican food" and "Good for lunch"</p></div><div class="step step-level-1" step="13" id="classification-algorithms" data-rotate-z="0" data-rotate-x="0" data-rotate-y="0" data-x="-4000" data-y="5700" data-scale="1" data-z="-2000"><h1 id="classification-algorithms">Classification Algorithms</h1></div><div class="step step-level-1" step="14" id="tree-based" data-x="-4500" data-y="6500" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="tree-based">Tree-based</h1><ul><li>Decision Trees</li><li>Boosting, e.g. AdaBoost</li><li>Bootstrap Aggregation (Bagging)</li><li>Random Forest</li></ul></div><div class="step step-level-1" step="15" id="linear-other" data-x="-3500" data-y="6500" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="linear-and-other-classifiers">Linear and other classifiers</h1><ul><li>K Nearest Neighbors (KNN)</li><li>Logistic Regression (linear regression for binary classification)</li><li>Linear Discriminant Analysis (LDA)</li><li>Support Vector Machines</li><li>Perceptrons (the birth of the <strong>neural network</strong>)</li></ul></div><div class="step step-level-1" step="16" id="deep-learning" data-x="-3500" data-y="7300" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="neural-nets-the-whole-deep-learning-thing">Neural Nets &amp; the whole Deep Learning thing</h1><img src="images/neural_net.png"></img><p>Note: Deep Learning is not just big neural nets</p><p>Read <a href="http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/">A Brief History of Neural Nets and Deep Learning</a></p></div><div class="step step-level-1" step="17" id="tensorflow" data-x="-3500" data-y="8100" data-z="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><img src="images/tensorflow.png"></img></div><div class="step step-level-1" step="18" id="regression-classification-1" data-x="-1400" data-y="2500" data-z="-1000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="id3">Regression</h1><p>or</p><h1 id="id4">Classification</h1><p>What type of question needs to be asked of your data?</p></div><div class="step step-level-1" step="19" id="regression" data-scale="1" data-rotate-y="0" data-x="-500" data-y="3000" data-z="-2000" data-rotate-x="0" data-rotate-z="0"><h1 id="id5">Regression</h1><p>Question: <strong>How much</strong> y does this example have?</p><p>Dependent variable is <strong>quantitative / continuous</strong></p></div><div class="step step-level-1" step="20" id="linear-regression" data-x="-500" data-y="3800" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="-2000"><h1 id="simple-linear-regression">Simple Linear Regression</h1><img src="images/linear-regression.png"></img><p>(source: <a href="http://www-bcf.usc.edu/~gareth/ISL/">ISLR</a>)</p></div><div class="step step-level-1" step="21" id="fitting-model" data-x="300" data-y="4100" data-z="-1000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="fitting-training-a-model">Fitting / training a model</h1><p>Given assumptions about the relationship between your predictors and the outcome, estimate the parameters of that relationship.
In a simple linear relationship:</p><pre class="highlight ">y = a + bx (+ e)</pre><p>Fitting a model means finding what <strong>a</strong> and <strong>b</strong> should be. We <em>fit</em> them to the data we already have.</p></div><div class="step step-level-1" step="22" id="training" data-x="300" data-y="4600" data-z="-1000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><p>Training is the process by which we teach the model to fit the data. In simple linear regression we do this by getting it to minimize the <strong>Mean Squared Error (MSE)</strong>, which is the average difference between real values and predicted values.</p></div><div class="step step-level-1" step="23" id="gradient-descent" data-x="1300" data-y="4600" data-z="-1000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="gradient-descent">Gradient Descent</h1><p>You have a <strong>loss function</strong>, aka a <strong>cost function</strong>, which computes the error of your model, and it is a function of the parameters of the model. You need a procedure for minimizing that function with respect to the parameters.</p></div><div class="step step-level-1" step="24" id="prediction" data-x="300" data-y="5000" data-z="-1000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><p>Your prediction algorithm feeds new data into this model to predict the outcome.</p><p>Suppose you fit a simple linear model:</p><pre class="highlight ">y = a + bx</pre><p>and get a value of 5 for your <strong>a</strong> parameter and 2 for your <strong>b</strong> parameter.</p><p>If you feed an x value of 3 into this you'd get:</p><pre class="highlight ">y = 5 + (2 x 3) = 11</pre></div><div class="step step-level-1" step="25" id="multi-linear-regression" data-x="-500" data-y="5700" data-z="-2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="multiple-linear-regression">Multiple Linear Regression</h1><p>Predictors  == Features == Dimensions</p><img src="images/multi-linear-regression.png"></img><p>(source: <a href="http://www-bcf.usc.edu/~gareth/ISL/">ISLR</a> )</p></div><div class="step step-level-1" step="26" id="supervised-unsupervised-1" data-x="0" data-y="1200" data-z="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="id7">Supervised</h1><p>or</p><h1 id="id8">Unsupervised</h1><p>Different approaches for different types of problem</p></div><div class="step step-level-1" step="27" data-x="1500" data-z="-1000" data-y="2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="id9">Unsupervised</h1><p>Unlabeled data, i.e. no outcome variable, just a bunch of data that you are trying to find some hidden structure in.</p></div><div class="step step-level-1" step="28" id="kmeans" data-x="2700" data-y="1600" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="-1000"><h1 id="k-means-clustering">K-Means Clustering</h1><img src="images/kmeans1.jpg"></img><p>(source: <a href="http://sherrytowers.com/2013/10/24/k-means-clustering/">http://sherrytowers.com/2013/10/24/k-means-clustering/</a>)</p></div><div class="step step-level-1" step="29" id="pca" data-x="2700" data-y="2500" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="-1000"><h1 id="principal-component-analysis">Principal Component Analysis</h1><img src="images/pca.png"></img><p>(source: <a href="http://austingwalters.com/pca-principal-component-analysis/">http://austingwalters.com/pca-principal-component-analysis/</a>)</p></div><div class="step step-level-1" step="30" id="nlp" data-x="4000" data-y="0" data-z="3000" data-rotate-y="90" data-rotate-x="0" data-rotate-z="0" data-scale="1"><h1 id="natural-language-processing">Natural Language Processing</h1><p>Specialized techniques for working with textual data.</p><ul><li>predictive text</li><li>sentiment analysis</li><li>question answering</li><li>text generation using Markov Chains</li><li>machine translation</li></ul></div><div class="step step-level-1" step="31" id="bayesian-ml" data-x="0" data-y="4000" data-z="1000" data-rotate-y="0" data-rotate-x="90" data-rotate-z="0" data-scale="1"><h1 id="bayesian-machine-learning">Bayesian Machine Learning</h1><p>Also known as <em>model-based machine learning</em>. Separates model from inference method and uses <strong>probabilistic programming</strong> to refine models.</p><ul><li>Bayesian Inference</li><li>Latent variables</li><li>MCMC</li><li>Hyperparameters</li><li>BUGS, Church, Stan, PyMC</li></ul></div><div class="step step-level-1" step="32" id="concepts" data-x="-4000" data-y="-2000" data-z="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="random-tips">Random Tips:</h1></div><div class="step step-level-1" step="33" id="overfitting" data-x="-3000" data-y="-2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="0"><h1 id="avoid-overfitting">Avoid Overfitting</h1><p>Overfitting is when your model fits your training data really well but doesn't generalize well to new data.</p></div><div class="step step-level-1" step="34" id="biased" data-x="-2000" data-y="-2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="0"><h1 id="underfitting-high-bias">Underfitting: High Bias</h1><img src="images/biased.png"></img></div><div class="step step-level-1" step="35" id="variance" data-x="-1000" data-y="-2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="0"><h1 id="overfitting-high-variance">Overfitting: High Variance</h1><img src="images/variance.png"></img></div><div class="step step-level-1" step="36" id="regularization" data-x="0" data-y="-2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="0"><h1 id="regularization">Regularization</h1><p>"Shrink" your parameters by adding a penalty. In neural nets this is called "weight decay."</p><p>This helps avoid overfitting. If you are underfitting, your model is not sophisticated enough, consider adding more features.</p></div><div class="step step-level-1" step="37" id="validation" data-x="1000" data-y="-2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="0"><h1 id="use-a-validation-set">Use a validation set</h1><p>Don't just split your data into a test set and a training set. The temptation will be too great to tweak the model based on its performance on the test set.</p><p>Use a validation set for this, otherwise your test set error is not a good indicator of what the error will be on unseen data.</p></div><div class="step step-level-1" step="38" id="singularity" data-x="6000" data-y="-3000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-z="0"><h1 id="the-singularity">The <strong>Singularity</strong></h1><h1 id="is-it-near-or-far">Is it <strong>Near</strong> or <strong>Far</strong>?</h1></div><div class="step step-level-1" step="39" id="exponential-growth" data-x="5300" data-y="-1900" data-z="2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><h1 id="near-because-exponential-growth">Near. Because Exponential Growth</h1><img src="images/exponential.png"></img></div><div class="step step-level-1" step="40" id="intelligence" data-x="6600" data-y="-1500" data-z="-2000" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1"><img src="images/figure-out-intelligence.png"></img><p>from <a href="https://twitter.com/mlittmancs/status/687023770943516672">Michael Littman</a></p></div><div class="step step-level-1" step="41" id="final" data-x="-1000" data-y="2500" data-z="2000" data-scale="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0"><h1 id="questions">Questions? :)</h1></div></div><div id="hovercraft-help"><table><tr><th>Space</th><td>Forward</td></tr><tr><th>Right, Down, Page Down</th><td>Next slide</td></tr><tr><th>Left, Up, Page Up</th><td>Previous slide</td></tr><tr><th>P</th><td>Open presenter console</td></tr><tr><th>H</th><td>Toggle this help</td></tr></table></div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/impressConsole.js"></script><script type="text/javascript" src="js/hovercraft.js"></script></body></html>